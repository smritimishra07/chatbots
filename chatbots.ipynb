{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() ## aloading all the environment variable\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "groq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002ADD6A02960>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002ADD6A033B0>, model_name='Gemma2-9b-It', groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"Gemma2-9b-It\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Smriti,\\n\\nIt's nice to meet you! Welcome to Valuebound.\\n\\nIs there anything I can help you with today? I'm here to assist with any questions you might have or tasks you need help with.\\n\", response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 29, 'total_tokens': 80, 'completion_time': 0.105761085, 'prompt_time': 0.004401665, 'queue_time': None, 'total_time': 0.11016275}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-bad17928-e34b-40bd-bcd3-127ec0a36abd-0', usage_metadata={'input_tokens': 29, 'output_tokens': 51, 'total_tokens': 80})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi , My name is Smriti and I am an intern at Valuebound\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You are Smriti, an intern at Valuebound! üòä \\n\\nIs there anything specific you'd like to talk about regarding your work at Valuebound?  I'm here to listen and chat.  \\n\", response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 106, 'total_tokens': 152, 'completion_time': 0.094034776, 'prompt_time': 0.017263443, 'queue_time': None, 'total_time': 0.111298219}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-54765c9c-44cc-48f4-8e4a-558bd4b0499d-0', usage_metadata={'input_tokens': 106, 'output_tokens': 46, 'total_tokens': 152})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi , My name is Smriti and I am an intern at Valuebound\"),\n",
    "        AIMessage(content=\"Hello Smriti! It's nice to meet you. \\n\\nAs an intern at Valuebound, what kind of projects are you working on these days? \\n\\nI'm always eager to learn more about the exciting work being done in the field of AI.\\n\"),\n",
    "        HumanMessage(content=\"Hey What's my name and what do I do?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Message History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (0.2.12)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from langchain_community) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from langchain_community) (3.10.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.13 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from langchain_community) (0.2.13)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.30 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from langchain_community) (0.2.30)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from langchain_community) (0.1.99)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from langchain<0.3.0,>=0.2.13->langchain_community) (0.2.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from langchain<0.3.0,>=0.2.13->langchain_community) (2.8.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.30->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain_community) (2.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\smrit\\langchain\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: ValueError()\n",
      "Error in callback coroutine: ValueError()\n"
     ]
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi , My name is Smriti and I am an intern at Valuebound\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Smriti, it's nice to meet you! \\n\\nWelcome to Valuebound. I'm glad to hear you're interning there. What are you working on during your internship? \\n\\nI'm an AI, so I can't offer any specific advice about your work, but I'm happy to chat and answer any general questions you might have.\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: ValueError()\n",
      "Error in callback coroutine: ValueError()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Smriti!  \\n\\nYou told me at the beginning of our conversation. üòä  \\n', response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 124, 'total_tokens': 147, 'completion_time': 0.046397195, 'prompt_time': 0.021165629, 'queue_time': None, 'total_time': 0.067562824}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-4da33361-e2a1-4db1-a721-18c3e49e0096-0', usage_metadata={'input_tokens': 124, 'output_tokens': 23, 'total_tokens': 147})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: ValueError()\n",
      "Error in callback coroutine: ValueError()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations or access to personal information about you, including your name. If you'd like to tell me your name, I'd be happy to use it!\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## change the config-->session id\n",
    "config1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Whats my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: ValueError()\n",
      "Error in callback coroutine: ValueError()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hi Smriti, it's nice to meet you! \\n\\nIs there anything I can help you with today? üòä  \\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey My name is Smriti\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: ValueError()\n",
      "Error in callback coroutine: ValueError()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Smriti!  üòä  I remember now. \\n\\nIs there anything else I can help you with? \\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Whats my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant.Amnswer all the question to the nest of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Smriti, it's nice to meet you! üëã \\n\\nHow can I help you today? üòä  \\n\", response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 37, 'total_tokens': 64, 'completion_time': 0.05412774, 'prompt_time': 0.002932977, 'queue_time': None, 'total_time': 0.057060717}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-b94eef42-6826-4448-b038-0f81c66b5626-0', usage_metadata={'input_tokens': 37, 'output_tokens': 27, 'total_tokens': 64})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi My name is Smriti\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: ValueError()\n",
      "Error in callback coroutine: ValueError()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Smriti, it's nice to meet you! \\n\\nHow can I help you today? üòä  \\n\\n\", response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 37, 'total_tokens': 64, 'completion_time': 0.054449134, 'prompt_time': 0.003270624, 'queue_time': None, 'total_time': 0.057719758}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-75f54569-25a0-4445-b482-0560956de7ab-0', usage_metadata={'input_tokens': 37, 'output_tokens': 27, 'total_tokens': 64})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat3\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi My name is Smriti\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: ValueError()\n",
      "Error in callback coroutine: ValueError()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Smriti.  \\n\\nI remember! üòä\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add more complexity\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á Smriti!  \\n\\n‡§Æ‡•Å‡§ù‡•á ‡§Ü‡§™‡§∏‡•á ‡§Æ‡§ø‡§≤‡§ï‡§∞ ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§≤‡§ó‡§æ‡•§  ‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç? \\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke({\"messages\":[HumanMessage(content=\"Hi My name is Smriti\")],\"language\":\"Hindi\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: ValueError()\n",
      "Error in callback coroutine: ValueError()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á Smriti, ‡§Ü‡§™‡§ï‡§æ ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§π‡•à!  ‡§Æ‡•Å‡§ù‡•á ‡§Ü‡§™‡§∏‡•á ‡§¨‡§æ‡§§ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à‡•§ üòä \\n\\n‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§™‡•Ç‡§õ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•Ä ‡§π‡•à‡§Ç? \\n\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat4\"}}\n",
    "repsonse=with_message_history.invoke(\n",
    "    {'messages': [HumanMessage(content=\"Hi,I am Smriti\")],\"language\":\"Hindi\"},\n",
    "    config=config\n",
    ")\n",
    "repsonse.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: ValueError()\n",
      "Error in callback coroutine: ValueError()\n"
     ]
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"whats my name?\")], \"language\": \"Hindi\"},\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ Smriti ‡§π‡•à‡•§ üòä  \\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Managing the Conversational History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\smrit\\LangChain\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\smrit\\LangChain\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\"),\n",
       " HumanMessage(content='I like vanilla ice cream'),\n",
       " AIMessage(content='nice'),\n",
       " HumanMessage(content='whats 2 + 2'),\n",
       " AIMessage(content='4'),\n",
       " HumanMessage(content='thanks'),\n",
       " AIMessage(content='no problem!'),\n",
       " HumanMessage(content='having fun?'),\n",
       " AIMessage(content='yes!')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=45,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I don't have access to your personal information, including your ice cream preferences.  \\n\\nWhat's your favorite flavor?  üç¶üòÑ\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    "    \n",
    ")\n",
    "\n",
    "response=chain.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"What ice cream do i like\")],\n",
    "    \"language\":\"English\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked \"what\\'s 2 + 2\".  üòä \\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what math problem did i ask\")],\n",
    "        \"language\": \"English\",\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets wrap this in the Message History\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")\n",
    "config={\"configurable\":{\"session_id\":\"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: ValueError()\n",
      "Error in callback coroutine: ValueError()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"As a large language model, I don't have access to any personal information about you, including your name. \\n\\nWould you like to tell me your name? üòä\\n\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"whats my name?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: ValueError()\n",
      "Error in callback coroutine: ValueError()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"As a large language model, I have no memory of past conversations. If you'd like to ask me a math problem, I'm happy to help! üòä  Just let me know what it is.  \\n\\n\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"what math problem did i ask?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
